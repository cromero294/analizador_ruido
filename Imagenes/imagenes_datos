A_moons.eps

  - Main origen:                pruebasMoons.py
  - Datos entrenamiento:        X,y=make_moons(n_samples=10000, shuffle=True, noise=0.5, random_state=None)
  - Datos test:                 Xt,yt=make_moons(n_samples=20000, shuffle=True, noise=0.5, random_state=None)
  - Numero datos entrenamiento: 10000
  - Numero datos test:          20000
  - Funcion entrenamiento:      entrenamiento(datostrain, 100, 0.5)
  - Conjunto clasificadores:    100, tree.DecisionTreeClassifier()
  - Porcentaje acierto:         0,8001 ~ 80,01%
  - Descripcion:                Imagen separada en cuatro recuadros. En el primer recuadro vemos el total de
                                los datos originales separados en dos clases. En el segundo, podemos ver los
                                datos modificados en la última iteración del entrenamiento, es decir, la
                                modificación aleatoria del 50% de las clases. En la tercera, podemos ver en
                                color verde los ejemplos que están bien clasificados y en rojo los que están
                                modificados en la última iteración del entrenamiento. Finalmente, en la cuarta
                                imagen, vemos la clasificación final de los elementos (bien clasificado en
                                verde, mal clasificado en rojo).

B_error_moons.eps

  - Main origen:                Main_error.py
  - Datos entrenamiento:        X,y=make_moons(n_samples=500, shuffle=True, noise=0.5, random_state=None)
  - Datos test:                 Xt,yt=make_moons(n_samples=20000, shuffle=True, noise=0.2, random_state=None)
  - Numero datos entrenamiento: 500
  - Numero datos test:          20000
  - Funcion entrenamiento:      entrenamiento(datostrain, 101, 0.5)
  - Conjunto clasificadores:    101, tree.DecisionTreeClassifier()
  - Descripcion:                En la imagen podemos observar el comportamiento de la tasa de fallos del algoritmo
                                al utilizar un entrenamiento de 101 árboles con 500 ejemplos y un conjunto de test
                                de 20000 ejemplos. El programa va probando, con el mismo conjunto de árboles pero
                                de uno en uno, con los datos de test y recoge su tasa de error frente al número de
                                árboles utilizado. A pesar de realizar la clasificación 10 veces para regular la gráfica
                                la función sale con sierra y creo que se puede deber al utilizar conjuntos pares de
                                árboles.

B_error_moons_impares.eps

  - Main origen:                Main_error.py
  - Datos entrenamiento:        X,y=make_moons(n_samples=500, shuffle=True, noise=0.5, random_state=None)
  - Datos test:                 Xt,yt=make_moons(n_samples=20000, shuffle=True, noise=0.2, random_state=None)
  - Numero datos entrenamiento: 500
  - Numero datos test:          20000
  - Funcion entrenamiento:      entrenamiento(datostrain, 101, 0.5)
  - Conjunto clasificadores:    101, tree.DecisionTreeClassifier()
  - Descripcion:                En la imagen podemos observar el comportamiento de la tasa de fallos del algoritmo
                                al utilizar un entrenamiento de 101 árboles con 500 ejemplos y un conjunto de test
                                de 20000 ejemplos. El programa va probando, con el mismo conjunto de árboles pero
                                de uno en uno, con los datos de test y recoge su tasa de error frente al número de
                                árboles utilizado. Se eliminan los conjuntos pares para que no exista opción de empate.

B_error_moons_impares_menos_datos.eps

  - Main origen:                Main_error.py
  - Datos entrenamiento:        X,y=make_moons(n_samples=500, shuffle=True, noise=0.5, random_state=None)
  - Datos test:                 Xt,yt=make_moons(n_samples=100, shuffle=True, noise=0.2, random_state=None)
  - Numero datos entrenamiento: 500
  - Numero datos test:          100
  - Funcion entrenamiento:      entrenamiento(datostrain, 501, 0.5)
  - Conjunto clasificadores:    501, tree.DecisionTreeClassifier()
  - Descripcion:                En la imagen podemos observar el comportamiento de la tasa de fallos del algoritmo
                                al utilizar un entrenamiento de 501 árboles con 500 ejemplos y un conjunto de test
                                de 100 ejemplos. Se hace la media de 100 clasificaciones para que no dentee la gráfica.
                                El programa va probando, con el mismo conjunto de árboles pero de uno en uno, con los
                                datos de test y recoge su tasa de error frente al número de árboles utilizado. Se
                                eliminan los conjuntos pares para que no exista opción de empate.

B_error_wdbc.eps

  - Main origen:                Main_error.py
  - Datos entrenamiento:        80%, wdbc.data
  - Datos test:                 20%, wdbc.data
  - Numero datos entrenamiento: 455
  - Numero datos test:          114
  - Funcion entrenamiento:      entrenamiento(datostrain, 100, 0.5)
  - Conjunto clasificadores:    100, tree.DecisionTreeClassifier()
  - Descripcion:                Se observa la tasa de fallo con respecto al número de clasificadores utilizado. Para
                                regular la gráfica se realiza la media de 100 clasificaciones distintas de los datos.
                                La gráfica sigue siendo demasiado irregular.

B_error_wdbc_impares.eps

  - Main origen:                Main_error.py
  - Datos entrenamiento:        80%, wdbc.data
  - Datos test:                 20%, wdbc.data
  - Numero datos entrenamiento: 455
  - Numero datos test:          114
  - Funcion entrenamiento:      entrenamiento(datostrain, 101, 0.5)
  - Conjunto clasificadores:    101, tree.DecisionTreeClassifier()
  - Descripcion:                Se observa la tasa de fallo con respecto al número de clasificadores utilizado. Para
                                regular la gráfica se realiza la media de 100 clasificaciones distintas de los datos.
                                La gráfica sigue siendo demasiado irregular. Se utilizan numeros impares de
                                clasificadores.

C_example1_mesh.eps, C_example3_mesh.eps, C_example4_mesh.eps

  - Main origen:                pruebas.py
  - Datos entrenamiento:        80%, example1.data, example3.data, example4.data,
  - Datos test:                 20%, example1.data, example3.data, example4.data,
  - Numero datos entrenamiento: 320, 320, 80
  - Numero datos test:          80, 80, 20
  - Funcion entrenamiento:      entrenamiento(datostrain, 100, 0.5)
  - Conjunto clasificadores:    100, tree.DecisionTreeClassifier()
  - Descripcion:                Se observa la clasificación de los datos y la forma de clasificar del conjunto. Para
                                realizar la imagen utilizamos los datos de test y la función plotModel, en la cual
                                generamos un conjunto de datos con .ravel y lo clasificamos para obtener su supuesta
                                clase real para, a continuación, generar el mesh del algoritmo de clasificación.


-------------------------------------------------------------------------------------------------------------------------------------

moons_20000.eps, moons_20000_impares.eps

  - Main origen:                Main_general.py
  - Datos entrenamiento:        X,y=make_moons(n_samples=500, shuffle=True, noise=0.5, random_state=None), variando por iteracion
  - Datos test:                 Xt,yt=make_moons(n_samples=20000, shuffle=True, noise=0.5, random_state=None), fijo
  - Numero datos entrenamiento: 500
  - Numero datos test:          20000
  - Funcion entrenamiento:      entrenamiento(datostrain, 100, 0.5)
  - Conjunto clasificadores:    100, tree.DecisionTreeClassifier()
  - Descripcion:                Se puede observar el porcentaje de error frente al numero de clasificadores utilizado en el
                                conjunto. En una de las pruebas se hace con comprobaciones pares y en el otro con impares.
                                La forma de realizarlo ha sido la siguiente: Se genera un conjunto de test fijo y después se
                                realizan 100 iteraciones generando nuevos datos de entrenamiento por cada iteracion. Se clasifican
                                los datos de test con 1 - 100 (arboles en este caso) y sigue el bucle. Para clasificar primero se
                                guardan las votaciones con todos los arboles y luego se clasifica.
